{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Calvano et al. (2020)\n",
    "## Baseline - Stat des - Convergence\n",
    "### Author: Andr√©a Epivent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "# Import packages\n",
    "exec(open(path+\"/packages.py\").read())\n",
    "\n",
    "# Import custom functions\n",
    "from functions import *\n",
    "\n",
    "# Import parameters\n",
    "exec(open(path+\"/parameters.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from training\n",
    "q_table_1 = np.load(path+'/Output/Baseline/q_table_a1.npy')\n",
    "q_table_2 = np.load(path+'/Output/Baseline/q_table_a2.npy')\n",
    "A = np.load(path+'/Output/Baseline/actions.npy')\n",
    "S = np.load(path+'/Output/Baseline/states.npy')\n",
    "conv_info = np.load(path+'/Output/Baseline/conv_info.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average number of iterations per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1873408.56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_info[0,:].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of iterations that did not converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(conv_info[0,:] == criterion_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Idea</b>: check that optimal actions don't change when we turn exploration off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock last price for both agents for each episode\n",
    "price1, price2 = conv_info[1,:], conv_info[2,:]\n",
    "threshold = 1e4\n",
    "conv_episodes = []\n",
    "\n",
    "for j in range(n_episodes): \n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    # Import q-matrix of both agents\n",
    "    q1 = q_table_1[(j+1)*225:(j+1)*225+225,:]\n",
    "    q2 = q_table_2[(j+1)*225:(j+1)*225+225,:]\n",
    "        \n",
    "    # Find last state and optimal action response according to limit strategy\n",
    "    state = find_rowindex(S,price1[j],price2[j])\n",
    "        \n",
    "    # Initialize convergence criteria\n",
    "    convergence = False\n",
    "    \n",
    "    # Initialize matrix for keeping track of argmax_p q\n",
    "    stab1 = np.full([state_space],-1)\n",
    "    stab2 = np.full([state_space],-1)\n",
    "\n",
    "    while convergence == False:\n",
    "\n",
    "        # Find optimal actions and keep track\n",
    "        action_a1 = np.argmax(q1[state])\n",
    "        action_a2 = np.argmax(q2[state])\n",
    "        \n",
    "        # Retrieve prices and next state\n",
    "        p1,p2 = A[action_a1], A[action_a2]\n",
    "        next_state = find_rowindex(S,p1,p2) # We find the row index associated with these two new prices\n",
    "\n",
    "        # Rewards\n",
    "        reward_a1 = profit_compute(p1,p2)\n",
    "        reward_a2 = profit_compute(p2,p1)\n",
    "\n",
    "        # Updating Q-table - for agent 1 \n",
    "        old_value_a1 = q1[state, action_a1]\n",
    "        next_max_a1 = np.max(q1[next_state])\n",
    "\n",
    "        new_value_a1 = (1 - alpha) * old_value_a1 + alpha * (reward_a1 + delta * next_max_a1)\n",
    "        q1[state, action_a1] = new_value_a1\n",
    "        \n",
    "        # Updating Q-table - for agent 2\n",
    "        old_value_a2 = q2[state, action_a2]\n",
    "        next_max_a2 = np.max(q2[next_state])\n",
    "\n",
    "        new_value_a2 = (1 - alpha) * old_value_a2 + alpha * (reward_a2 + delta * next_max_a2)\n",
    "        q2[state, action_a2] = new_value_a2\n",
    "\n",
    "        # Stop if optimal action changes\n",
    "        if (action_a1 != stab1[state]) & (stab1[state] != -1):\n",
    "            convergence = True\n",
    "            print(f\"Agent 1 changed optimal action at stage {state} and period {t}\")\n",
    "            conv_episodes.append(False)\n",
    "        \n",
    "        if (action_a2 != stab2[state]) & (stab2[state] != -1):\n",
    "            convergence = True\n",
    "            print(f\"Agent 2 changed optimal action at stage {state} and period {t}\")\n",
    "        \n",
    "        stab1[state] = action_a1\n",
    "        stab2[state] = action_a2\n",
    "        \n",
    "        # We always stick to the same state\n",
    "        state = next_state\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "        # Stop in any case\n",
    "        if t == threshold:\n",
    "            convergence = True\n",
    "            conv_episodes.append(True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_episodes.count(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
